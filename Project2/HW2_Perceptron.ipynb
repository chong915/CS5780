{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Project 2: The Perceptron</h2>\n",
    "\n",
    "\n",
    "<!--announcements-->\n",
    "<blockquote>\n",
    "    <center>\n",
    "    <img src=\"perceptron.png\" width=\"200px\" />\n",
    "    </center>\n",
    "      <p><cite><center>\"What, we asked, wasn't the Perceptron capable of?\"<br>\n",
    "      Rival, The New Yorker, December 6, 1958 P. 44</center>\n",
    "      </cite></p>\n",
    "</blockquote>\n",
    "\n",
    "<h3>Introduction</h3>\n",
    "<!--AÃ°albrandr-->\n",
    "\n",
    "<p>In this project, you will implement a simple Perceptron classifier to classify digits (or anything else).</p>\n",
    "\n",
    "<strong>How to submit:</strong> You can submit your code using the red <strong>Submit</strong> button above. This button will send any code below surrounded by <strong>#&lt;GRADED&gt;</strong><strong>#&lt;/GRADED&gt;</strong> tags below to the autograder, which will then run several tests over your code. By clicking on the <strong>Details</strong> dropdown next to the Submit button, you will be able to view your submission report once the autograder has completed running. This submission report contains a summary of the tests you have failed or passed, as well as a log of any errors generated by your code when we ran it.\n",
    "\n",
    "Note that this may take a while depending on how long your code takes to run! Once your code is submitted you may navigate away from the page as you desire -- the most recent submission report will always be available from the Details menu.\n",
    "\n",
    "<p><strong>Evaluation:</strong> Your code will be autograded for technical\n",
    "correctness. Please <em>do not</em> change the names of any provided functions or classes within the code, or you will wreak havoc on the autograder. However, the correctness of your implementation -- not the autograder's output -- will be the final judge of your score.  If necessary, we will review and grade assignments individually to ensure that you receive due credit for your work.\n",
    "\n",
    "<p><strong>Academic Dishonesty:</strong> We will be checking your code against other submissions in the class for logical redundancy. If you copy someone else's code and submit it with minor changes, we will know. These cheat detectors are quite hard to fool, so please don't try. We trust you all to submit your own work only; <em>please</em> don't let us down. If you do, we will pursue the strongest consequences available to us.\n",
    "\n",
    "<p><strong>Getting Help:</strong> You are not alone!  If you find yourself stuck  on something, contact the course staff for help.  Office hours, section, and the <a href=\"https://piazza.com/class/icxgflcnpra3ko\">Piazza</a> are there for your support; please use them.  If you can't make our office hours, let us know and we will schedule more.  We want these projects to be rewarding and instructional, not frustrating and demoralizing.  But, we don't know when or how to help unless you ask.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Python initialization:</strong> Please run the following code to initialize your Python kernel. You should be running a version of Python 3.x. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.6.6\n"
     ]
    }
   ],
   "source": [
    "#<GRADED>\n",
    "import numpy as np\n",
    "from matplotlib import *\n",
    "#matplotlib.use('PDF')\n",
    "from pylab import *\n",
    "#</GRADED>\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# add p02 folder\n",
    "sys.path.insert(0, './p02/')\n",
    "\n",
    "%matplotlib notebook\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The Perceptron <b>(95 points)</b> </h3>\n",
    "\n",
    "<p>The perceptron is a basic linear classifier. The following questions will ask you to finish these functions in a pre-defined order. Unless specified otherwise, do not use loops.<br></p>\n",
    "\n",
    "<p>(a) Implement the process of updating the weight vector in the following function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def perceptronUpdate(x,y,w):\n",
    "    \"\"\"\n",
    "    function w=perceptronUpdate(x,y,w);\n",
    "    \n",
    "    Implementation of Perceptron weights updating\n",
    "    Input:\n",
    "    x : input vector of d dimensions (d)\n",
    "    y : corresponding label (-1 or +1)\n",
    "    w : weight vector of d dimensions\n",
    "    \n",
    "    Output:\n",
    "    w : weight vector after updating (d)\n",
    "    \"\"\"\n",
    "    assert(y in {-1,1})\n",
    "    assert(len(w.shape)==1), \"At the update w must be a vector not a matrix (try w=w.flatten())\"\n",
    "    assert(len(x.shape)==1), \"At the update x must be a vector not a matrix (try x=x.flatten())\"\n",
    "    \n",
    "    ## fill in code ...\n",
    "    \n",
    "    w = w + y*x\n",
    "    \n",
    "    ## ... until here\n",
    "    return w.flatten()\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you passed the update test : )\n"
     ]
    }
   ],
   "source": [
    "# test the update code:\n",
    "x=rand(5) # random weight vector\n",
    "w=rand(5) # random feature vector\n",
    "y=-1 # random label\n",
    "wnew=perceptronUpdate(x,y,w.copy()) # do a perceptron update\n",
    "assert(norm(wnew-w+x)<1e-10), \"perceptronUpdate didn't pass the test : (\" # if correct, this should return 0\n",
    "print(\"Looks like you passed the update test : )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(b) Implement function <b><code>perceptron</code></b>. This should contain a loop that calls \n",
    "<b><code>perceptronUpdate</code></b>\n",
    " until it converges or the maximum iteration count, 100, has been reached.\n",
    " Make sure you randomize the order of the training data on each iteration. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def perceptron(xs,ys):\n",
    "    \"\"\"\n",
    "    function w=perceptron(xs,ys);\n",
    "    \n",
    "    Implementation of a Perceptron classifier\n",
    "    Input:\n",
    "    xs : n input vectors of d dimensions (nxd)\n",
    "    ys : n labels (-1 or +1)\n",
    "    \n",
    "    Output:\n",
    "    w : weight vector (1xd)\n",
    "    b : bias term\n",
    "    \"\"\"\n",
    "\n",
    "    assert(len(xs.shape)==2), \"The first input to Perceptron must be a _matrix_ of row input vecdtors.\"\n",
    "    assert(len(ys.shape)==1), \"The second input to Perceptron must be a _vector_ of n labels (try ys.flatten()).\"\n",
    "        \n",
    "    n, d = xs.shape     # so we have n input vectors, of d dimensions each\n",
    "    \n",
    "    ## fill in code ...\n",
    "    \n",
    "    xs_homogeneous = np.concatenate((xs, np.ones((n, 1))), axis = 1) # Convert to homogeneous problem\n",
    "    \n",
    "    i = 0\n",
    "    w = np.zeros(d + 1) # Convert to homogeneous problem\n",
    "    while i < 1000:\n",
    "        order = np.random.permutation(n)\n",
    "        xs_perm = xs_homogeneous[order]\n",
    "        ys_perm = ys[order]\n",
    "        if(~(all(np.sign(ys*(xs.dot(w[:-1])+w[-1]))==1.0))):\n",
    "            j = 0\n",
    "            while j < d:\n",
    "                if(ys_perm[j] * np.dot(w, xs_perm[j]) <= 0):\n",
    "                    w = w + ys_perm[j] * xs_perm[j]\n",
    "                    print(np.linalg.norm(w))\n",
    "                j += 1\n",
    "        else:\n",
    "            break\n",
    "        i += 1\n",
    "    \n",
    "    b = w[-1] # Get bias from last element of homogeneous w vector\n",
    "    w = w[:-1] # non-homogeneous w vector is the first d elements of homogeneous solution\n",
    "    \n",
    "    ## ... until here\n",
    "    return (w,b)\n",
    "\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> You can use the following script to test your code and visualize your perceptron on linearly separable data in 2 dimensions. Your classifier should find a separating hyperplane on such data.   </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.317600796464397\n",
      "4.967204934117955\n",
      "4.037930993592776\n",
      "4.003162329432869\n",
      "4.452472013732921\n",
      "4.108534302462695\n",
      "4.267822357660931\n",
      "4.841598104262424\n",
      "6.500485951672908\n",
      "8.46937518440274\n",
      "8.46936243613921\n",
      "9.708916699263513\n",
      "9.651674835476223\n",
      "9.082923510996226\n",
      "9.391924436514413\n",
      "10.306004211845558\n",
      "10.75303741334652\n",
      "10.979759632176494\n",
      "10.93175223591029\n",
      "11.816583045977897\n",
      "12.013735568456225\n",
      "12.204142246763677\n",
      "12.902598072933271\n",
      "13.05378647188123\n",
      "13.26782834736438\n",
      "12.976967676846307\n",
      "13.213169600327442\n",
      "13.757456020543431\n",
      "13.76472147175531\n",
      "14.302078200493089\n",
      "14.092315213704177\n",
      "14.134281999246708\n",
      "14.383352851273003\n",
      "14.462406004901515\n",
      "14.787390125795332\n",
      "14.992408496948814\n",
      "15.551311582404786\n",
      "15.222380745663926\n",
      "15.250294373197235\n",
      "15.30850427950051\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of input vectors\n",
    "N = 100\n",
    "\n",
    "# generate random (linarly separable) data\n",
    "xs = np.random.rand(N, 2)*10-5\n",
    "\n",
    "# defining random hyperplane\n",
    "w0 = np.random.rand(2)\n",
    "b0 = rand()*2-1;\n",
    "\n",
    "# assigning labels +1, -1 labels depending on what side of the plane they lie on\n",
    "ys = np.sign(xs.dot(w0)+b0)\n",
    "\n",
    "# call perceptron to find w from data\n",
    "w,b = perceptron(xs.copy(),ys.copy())\n",
    "\n",
    "# test if all points are classified correctly\n",
    "assert (all(np.sign(ys*(xs.dot(w)+b))==1.0))  # yw'x should be +1.0 for every input\n",
    "\n",
    "# we can make a pretty visualizxation\n",
    "from helperfunctions import visboundary\n",
    "visboundary(w,b,xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    global w,b,ldata,ax,line,xydata\n",
    "\n",
    "    pos=np.array([[event.xdata],[event.ydata]])\n",
    "    if event.key == 'shift': # add positive point\n",
    "        color='or'\n",
    "        label=1\n",
    "    else: # add negative point\n",
    "        color='ob'\n",
    "        label=-1    \n",
    "    ax.plot(pos[0],pos[1],color)\n",
    "    ldata.append(label);\n",
    "    xydata=np.vstack((xydata,pos.T))\n",
    "    \n",
    "    # call Perceptron function\n",
    "    w,b=perceptron(xydata,np.array(ldata).flatten())\n",
    "\n",
    "    # draw decision boundary\n",
    "    q=-b/(w**2).sum() *w;\n",
    "    if line==None:\n",
    "        line, = ax.plot([q[0]-w[1],q[0]+w[1]],[q[1]+w[0],q[1]-w[0]],'b--')\n",
    "    else:\n",
    "        line.set_data([q[0]-w[1],q[0]+w[1]],[q[1]+w[0],q[1]-w[0]])\n",
    "        \n",
    "\n",
    "\n",
    "xydata=rand(0,2)\n",
    "ldata=[]\n",
    "w=zeros(2)\n",
    "b=0\n",
    "line=None\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "title('Use shift-click to add negative points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(c) \n",
    "\tImplement \n",
    "<b><code>classifyLinear</code></b>\n",
    " that applies the weight vector and bias to the input vector. (The bias is an optional parameter. If it is not passed in, assume it is zero.) Make sure that the predictions returned are either 1 or -1.</p> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def classifyLinear(xs,w,b):\n",
    "    \"\"\"\n",
    "    function preds=classifyLinear(xs,w,b)\n",
    "    \n",
    "    Make predictions with a linear classifier\n",
    "    Input:\n",
    "    xs : n input vectors of d dimensions (nxd) [could also be a single vector of d dimensions]\n",
    "    w : weight vector of dimensionality d\n",
    "    b : bias (scalar)\n",
    "    \n",
    "    Output:\n",
    "    preds: predictions (1xn)\n",
    "    \"\"\"    \n",
    "    w = w.flatten()    \n",
    "    predictions=np.zeros(xs.shape[0])\n",
    "    ## fill in code ...\n",
    "    ## ... until here\n",
    "    return predictions\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test classifyLinear code:\n",
    "xs=rand(1000,2)-0.5 # draw random data \n",
    "w0=np.array([0.5,-0.3]) # define a random hyperplane \n",
    "b0=-0.1 # with bias -0.1\n",
    "ys=np.sign(xs.dot(w0)+b0) # assign labels according to this hyperplane (so you know it is linearly separable)\n",
    "assert (all(np.sign(ys*classifyLinear(xs,w0,b0))==1.0))  # the original hyperplane (w0,b0) should classify all correctly\n",
    "print(\"Looks like you passed the classifyLinear test! :o)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Competition <b>(5 points)</b></h3>\n",
    "\n",
    "<p>The competition for this assignment is to achieve the highest accuracy on the hidden test set (randomly sampled) using the perceptron algorithm you implemented above. You will have access to a training, and a validation set but not the actual test set.\n",
    "    \n",
    "You will receive full points on this section as long as you beat a baseline which we have implemented.\n",
    "\n",
    "We will have a leaderboard once the assignement due date has passed showing how well you did on the test set.</p>\n",
    "\n",
    "<p>The competition for this assignment is split into two components you can modify:</p>\n",
    "\n",
    "<ol>\n",
    "<li><b>Feature Extraction</b>:\n",
    "Modify the function <code>extractfeaturescomp</code>.\n",
    "This function takes in a file path <code>path</code> and\n",
    "a feature dimension <code>B</code> and should output a feature vector of dimension <code>B</code>.\n",
    "The autograder will pass in a file path pointing to a file that contains an email,\n",
    "and set <code>B</code> = <code>feature_dimension</code>.\n",
    "We provide <code>extractfeaturesnaive</code> as an example.\n",
    "</li>\n",
    "<li><b>Model Training</b>:\n",
    "Modify the function <code>trainspamfiltercomp</code>.\n",
    "This function takes in training data <code>xTr</code> and training labels <code>yTr</code> and\n",
    "should output a weight vector <code>w</code> for linear classification. <b>You must use the perceptron algorithm implemented above </b> although you are free to tweak the parameters such as the number of iterations.\n",
    "We provide an initial implementation of a random classifier.\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "<p>Your model will be trained on the following dataset (loaded by <code>loadspamdata</code>), but we will test its accuracy on a secret dataset of emails.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the email and hashes the symbols into a vector\n",
    "def extractfeaturesnaive(path, B):\n",
    "    with open(path, 'r') as femail:\n",
    "        # initialize all-zeros feature vector\n",
    "        v = np.zeros(B)\n",
    "        email = femail.read()\n",
    "        # breaks for non-ascii characters\n",
    "        tokens = email.split()\n",
    "        breakpoint()\n",
    "        for token in tokens:\n",
    "            v[hash(token) % B] = 1\n",
    "    return v\n",
    "\n",
    "def loadspamdata(extractfeatures, B=256, path=\"../resource/lib/public/new_train_data/\"):\n",
    "    '''\n",
    "    INPUT:\n",
    "    extractfeatures : function to extract features\n",
    "    B               : dimensionality of feature space\n",
    "    path            : the path of folder to be processed\n",
    "    \n",
    "    OUTPUT:\n",
    "    X, Y\n",
    "    '''\n",
    "    if path[-1] != '/':\n",
    "        path += '/'\n",
    "    \n",
    "    with open(path + 'index', 'r') as f:\n",
    "        allemails = [x for x in f.read().split('\\n') if ' ' in x]\n",
    "    \n",
    "    xs = np.zeros((len(allemails), B))\n",
    "    ys = np.zeros(len(allemails))\n",
    "    for i, line in enumerate(allemails):\n",
    "        label, filename = line.split(' ')\n",
    "        # make labels +1 for \"spam\" and -1 for \"ham\"\n",
    "        ys[i] = (label == 'spam') * 2 - 1\n",
    "        xs[i, :] = extractfeatures(path + filename, B)\n",
    "    print('Loaded %d input emails.' % len(ys))\n",
    "    return xs, ys\n",
    "\n",
    "X,Y = loadspamdata(extractfeaturesnaive)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your training set. To do proper model selection and avoid overfitting, you should split it off into a validation set. Here's one implementation but feel free to <b> try other methods including k-fold cross validation </b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "\n",
    "def validation_split(X, Y):\n",
    "    # Split data into training and validation\n",
    "    n, d = X.shape\n",
    "    cutoff = int(np.ceil(0.8 * n))\n",
    "    # indices of training samples\n",
    "    xTr = X[:cutoff,:]\n",
    "    yTr = Y[:cutoff]\n",
    "    # indices of validation samples\n",
    "    xTv = X[cutoff:,:]\n",
    "    yTv = Y[cutoff:]\n",
    "\n",
    "    ## fill in code ...\n",
    "    ## ... until here\n",
    "    \n",
    "    return xTr, yTr, xTv, yTv\n",
    "\n",
    "#</GRADED>\n",
    "\n",
    "xTr, yTr, xTv, yTv = validation_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This should generate a training data set <code>xTr</code>, <code>yTr</code> and a validation set <code>xTv</code>, <code>yTv</code> for you. </p>\n",
    "\n",
    "<p>It is now time to implement your classifiers.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "## do NOT change feature_dimension\n",
    "feature_dimension = 256\n",
    "\n",
    "def extractfeaturescomp(path, B):\n",
    "    '''\n",
    "    INPUT:\n",
    "    path : file path of email\n",
    "    B    : dimensionality of feature vector\n",
    "    \n",
    "    OUTPUTS:\n",
    "    x    : B dimensional vector\n",
    "    '''\n",
    "    ## naive implementation (same as extractfeaturesnaive(path, B))\n",
    "    x = np.zeros(B)\n",
    "    with open(path, 'r') as femail:\n",
    "        email = femail.read()\n",
    "        tokens = email.split()\n",
    "        for token in tokens:\n",
    "            x[hash(token) % B] = 1\n",
    "            \n",
    "    ## fill in code ...\n",
    "    ## your implementation\n",
    "    \n",
    "    ## ... until here\n",
    "    \n",
    "    return x\n",
    "    \n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def trainspamfiltercomp(xTr, yTr):\n",
    "    '''\n",
    "    INPUT:\n",
    "    xTr : nxd dimensional matrix (each row is an input vector)\n",
    "    yTr : d   dimensional vector (each entry is a label)\n",
    "    \n",
    "    OUTPUTS:\n",
    "    w : d dimensional vector for linear classification\n",
    "    '''\n",
    "    w = np.random.rand(np.shape(xTr)[1])\n",
    "    b = np.random.rand()\n",
    "    \n",
    "    ## fill in code ...\n",
    "    ## ... until here    \n",
    "    \n",
    "    return w,b\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate the performance on your validation set here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
